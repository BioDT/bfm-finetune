{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40da900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from aurora import Aurora\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from bfm_finetune.aurora_mod import AuroraFlex, AuroraRaw\n",
    "from bfm_finetune import plots_v2\n",
    "from bfm_finetune.dataloaders.geolifeclef_species.dataloader import GeoLifeCLEFSpeciesDataset\n",
    "from bfm_finetune.dataloaders.dataloader_utils import custom_collate_fn\n",
    "from bfm_finetune.utils import load_checkpoint, seed_everything, load_config\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c15d6ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Aurora(use_lora=True) # stabilise_level_agg=True\n",
    "base_model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-pretrained.ckpt\", strict=False) # strict=False\n",
    "atmos_levels = (50, 100, 150, 200, 250, 300, 400, 500, 600, 700, 850, 925, 1000)\n",
    "base_model.to(device)\n",
    "\n",
    "num_species = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb6853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = \"/home/thanasis.trantas/github_projects/bfm-finetune/outputs/2025-04-29/16-59-52\"\n",
    "# PATH = \"/home/martino.mensio/projects/bfm/bfm-finetune/outputs/2025-04-30/09-39-45\"\n",
    "# PATH = \"/home/thanasis.trantas/github_projects/bfm-finetune/outputs/2025-05-06/10-13-15-good-to-t1-only\"\n",
    "PATH = \"/home/tkhan/bfm-finetune/outputs/2025-06-15/18-46-07\"\n",
    "CHECKPOINT_PATH = Path(PATH) / \"checkpoints\"\n",
    "cfg = load_config(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e186304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files 1\n"
     ]
    }
   ],
   "source": [
    "val_dataset = GeoLifeCLEFSpeciesDataset(num_species=num_species, mode=\"val\", negative_lon_mode=cfg.dataset.negative_lon_mode)\n",
    "val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        collate_fn=custom_collate_fn,\n",
    "        num_workers=1,\n",
    "    )\n",
    "\n",
    "lat_lon = val_dataset.get_lat_lon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d72a195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA]  trainable params = 192 layers\n",
      "3.87 M / 1243.82 M parameters will update\n"
     ]
    }
   ],
   "source": [
    "# model = AuroraFlex(base_model=base_model, in_channels=num_species, hidden_channels=160,\n",
    "#                     out_channels=num_species, atmos_levels=atmos_levels, lat_lon=lat_lon,\n",
    "#                     supersampling_cfg=cfg.model.supersampling)\n",
    "model = AuroraRaw(base_model)\n",
    "model.to(device)\n",
    "\n",
    "params_to_optimize = model.parameters()\n",
    "optimizer = torch.optim.AdamW(params_to_optimize, lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da8402b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m _, _ = \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHECKPOINT_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/home1/tkhan/bfm-finetune/bfm_finetune/utils.py:157\u001b[39m, in \u001b[36mload_checkpoint\u001b[39m\u001b[34m(model, optimizer, checkpoint_folder)\u001b[39m\n\u001b[32m    155\u001b[39m file_path = os.path.join(checkpoint_folder, \u001b[33m\"\u001b[39m\u001b[33mbest_checkpoint.pth\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.isfile(file_path):\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     checkpoint = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m     model.load_state_dict(checkpoint[\u001b[33m\"\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    159\u001b[39m     optimizer.load_state_dict(checkpoint[\u001b[33m\"\u001b[39m\u001b[33moptimizer_state_dict\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bfm-finetune/.venv/lib/python3.12/site-packages/torch/serialization.py:1360\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1358\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1359\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1360\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1364\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1366\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1367\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[32m   1368\u001b[39m     f_name = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bfm-finetune/.venv/lib/python3.12/site-packages/torch/serialization.py:1848\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   1847\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m1848\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1849\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1851\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bfm-finetune/.venv/lib/python3.12/site-packages/torch/serialization.py:1812\u001b[39m, in \u001b[36m_load.<locals>.persistent_load\u001b[39m\u001b[34m(saved_id)\u001b[39m\n\u001b[32m   1810\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1811\u001b[39m     nbytes = numel * torch._utils._element_size(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m1812\u001b[39m     typed_storage = \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1813\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1814\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1816\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bfm-finetune/.venv/lib/python3.12/site-packages/torch/serialization.py:1784\u001b[39m, in \u001b[36m_load.<locals>.load_tensor\u001b[39m\u001b[34m(dtype, numel, key, location)\u001b[39m\n\u001b[32m   1779\u001b[39m         storage.byteswap(dtype)\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[32m   1783\u001b[39m typed_storage = torch.storage.TypedStorage(\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     wrap_storage=\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1785\u001b[39m     dtype=dtype,\n\u001b[32m   1786\u001b[39m     _internal=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   1787\u001b[39m )\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typed_storage._data_ptr() != \u001b[32m0\u001b[39m:\n\u001b[32m   1790\u001b[39m     loaded_storages[key] = typed_storage\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bfm-finetune/.venv/lib/python3.12/site-packages/torch/serialization.py:601\u001b[39m, in \u001b[36mdefault_restore_location\u001b[39m\u001b[34m(storage, location)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    582\u001b[39m \u001b[33;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[32m    583\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    598\u001b[39m \u001b[33;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[32m--> \u001b[39m\u001b[32m601\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    603\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bfm-finetune/.venv/lib/python3.12/site-packages/torch/serialization.py:539\u001b[39m, in \u001b[36m_deserialize\u001b[39m\u001b[34m(backend_name, obj, location)\u001b[39m\n\u001b[32m    537\u001b[39m     backend_name = torch._C._get_privateuse1_backend_name()\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m location.startswith(backend_name):\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     device = \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    540\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.to(device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bfm-finetune/.venv/lib/python3.12/site-packages/torch/serialization.py:508\u001b[39m, in \u001b[36m_validate_device\u001b[39m\u001b[34m(location, backend_name)\u001b[39m\n\u001b[32m    506\u001b[39m     device_index = device.index \u001b[38;5;28;01mif\u001b[39;00m device.index \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[33m\"\u001b[39m\u001b[33mis_available\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module.is_available():\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    509\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.is_available() is False. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    511\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf you are running on a CPU-only machine, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    512\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    513\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mto map your storages to the CPU.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m     )\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[33m\"\u001b[39m\u001b[33mdevice_count\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    516\u001b[39m     device_count = device_module.device_count()\n",
      "\u001b[31mRuntimeError\u001b[39m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "_, _ = load_checkpoint(model, optimizer, CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plots_v2)\n",
    "import bfm_finetune.metrics as UM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "crps_sum, dev_sum, d2_sum, tss_sum, n = 0, 0, 0, 0, 0\n",
    "for sample in val_dataloader:\n",
    "    batch = sample[\"batch\"]# .to(device)\n",
    "    batch[\"species_distribution\"] = batch[\"species_distribution\"].to(device)\n",
    "    target = sample[\"target\"]\n",
    "    with torch.inference_mode():\n",
    "        prediction = model.forward(batch)\n",
    "        unnormalized_preds = val_dataset.scale_species_distribution(prediction.clone(), unnormalize=True)\n",
    "    # plot_channel_time_slices(batch[\"species_distribution\"], channel_idx=0, cmap='plasma')\n",
    "    # plot_channel_time_slices(prediction, channel_idx=0, cmap='plasma')\n",
    "    un_preds = torch.nan_to_num(unnormalized_preds.float(), nan=0.0).clamp(min=0)\n",
    "\n",
    "    plots_v2.plot_eval(batch, un_preds, Path(\".\"), n_species_to_plot=1, save=False)\n",
    "    print(\"Preds shape\", unnormalized_preds.shape)\n",
    "    # ---- metrics ------------------------------------------------------ #\n",
    "    un_preds = un_preds.squeeze(0) # Remove the batch dim\n",
    "    target_yr2 = batch[\"species_distribution\"][:, 1]  # second year\n",
    "    crps_sum += UM.crps(un_preds, target_yr2).item()\n",
    "    dev = UM.poisson_deviance(un_preds, target_yr2)\n",
    "    d2_sum += UM.explained_deviance(un_preds, target_yr2).item()\n",
    "    dev_sum += dev.item()\n",
    "    tss_sum += UM.tss(un_preds, target_yr2).item()\n",
    "    n += 1\n",
    "metrics = {\n",
    "    \"CRPS\": crps_sum / n,\n",
    "    \"PoissonDev\": dev_sum / n,\n",
    "    \"D2\": d2_sum / n,\n",
    "    \"TSS\": tss_sum / n,\n",
    "}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bfm_finetune.vis_tools import plot_change_map, plot_confusion_map, plot_taylor_single, plot_hexbin, plot_error_violin\n",
    "lon = batch[\"metadata\"][\"lon\"].cpu().numpy()\n",
    "lat = batch[\"metadata\"][\"lat\"].cpu().numpy()\n",
    "species_i = 42\n",
    "\n",
    "species_subset = [0, 1, 2] # select species\n",
    "for s in species_subset:\n",
    "    y0       = batch[\"species_distribution\"][0, 0, s].cpu()\n",
    "    y1_true  = batch[\"species_distribution\"][0, 1, s].cpu()\n",
    "    y1_pred  = un_preds[0, s].cpu()\n",
    "    plot_change_map(lat, lon, y0, y1_true, y1_pred, s)\n",
    "    # plot_taylor(lat, lon, y1_true.numpy(), y1_pred.numpy())\n",
    "    # plot_taylor_single(y0.numpy().ravel(), y1_pred.numpy().ravel(), title=\"Yearâ€‘1 spatial skill\")\n",
    "    plot_confusion_map(lat, lon, y1_true.numpy(), y1_pred.numpy())\n",
    "\n",
    "# global calibration\n",
    "obs_all  = batch[\"species_distribution\"][:, 1].reshape(-1).cpu()\n",
    "pred_all = un_preds.reshape(-1).cpu()\n",
    "plot_hexbin(pred_all, obs_all)\n",
    "\n",
    "# violin of absolute errors  [species, cells]\n",
    "abs_err = torch.abs(un_preds - batch[\"species_distribution\"][:, 1]).cpu()\n",
    "plot_error_violin(abs_err.reshape(500, -1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cef5c45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
