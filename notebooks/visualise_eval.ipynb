{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from aurora import Aurora\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from bfm_finetune.aurora_mod import AuroraFlex, AuroraRaw\n",
    "from bfm_finetune import plots_v2\n",
    "from bfm_finetune.dataloaders.geolifeclef_species.dataloader import GeoLifeCLEFSpeciesDataset\n",
    "from bfm_finetune.dataloaders.dataloader_utils import custom_collate_fn\n",
    "from bfm_finetune.utils import load_checkpoint, seed_everything, load_config\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d6ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Aurora(use_lora=True) # stabilise_level_agg=True\n",
    "base_model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-pretrained.ckpt\", strict=False) # strict=False\n",
    "atmos_levels = (50, 100, 150, 200, 250, 300, 400, 500, 600, 700, 850, 925, 1000)\n",
    "base_model.to(device)\n",
    "\n",
    "num_species = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb6853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = \"/home/thanasis.trantas/github_projects/bfm-finetune/outputs/2025-04-29/16-59-52\"\n",
    "# PATH = \"/home/martino.mensio/projects/bfm/bfm-finetune/outputs/2025-04-30/09-39-45\"\n",
    "# PATH = \"/home/thanasis.trantas/github_projects/bfm-finetune/outputs/2025-05-06/10-13-15-good-to-t1-only\"\n",
    "PATH = \"/home/thanasis.trantas/github_projects/bfm-finetune/outputs/2025-05-06/15-33-56-MAE-best\"\n",
    "CHECKPOINT_PATH = Path(PATH) / \"checkpoints\"\n",
    "cfg = load_config(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e186304",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = GeoLifeCLEFSpeciesDataset(num_species=num_species, mode=\"val\", negative_lon_mode=cfg.dataset.negative_lon_mode)\n",
    "val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        collate_fn=custom_collate_fn,\n",
    "        num_workers=1,\n",
    "    )\n",
    "\n",
    "lat_lon = val_dataset.get_lat_lon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d72a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AuroraFlex(base_model=base_model, in_channels=num_species, hidden_channels=160,\n",
    "#                     out_channels=num_species, atmos_levels=atmos_levels, lat_lon=lat_lon,\n",
    "#                     supersampling_cfg=cfg.model.supersampling)\n",
    "model = AuroraRaw(base_model)\n",
    "model.to(device)\n",
    "\n",
    "params_to_optimize = model.parameters()\n",
    "optimizer = torch.optim.AdamW(params_to_optimize, lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = load_checkpoint(model, optimizer, CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plots_v2)\n",
    "import bfm_finetune.metrics as UM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "crps_sum, dev_sum, d2_sum, tss_sum, n = 0, 0, 0, 0, 0\n",
    "for sample in val_dataloader:\n",
    "    batch = sample[\"batch\"]# .to(device)\n",
    "    batch[\"species_distribution\"] = batch[\"species_distribution\"].to(device)\n",
    "    target = sample[\"target\"]\n",
    "    with torch.inference_mode():\n",
    "        prediction = model.forward(batch)\n",
    "        unnormalized_preds = val_dataset.scale_species_distribution(prediction.clone(), unnormalize=True)\n",
    "    # plot_channel_time_slices(batch[\"species_distribution\"], channel_idx=0, cmap='plasma')\n",
    "    # plot_channel_time_slices(prediction, channel_idx=0, cmap='plasma')\n",
    "    un_preds = torch.nan_to_num(unnormalized_preds.float(), nan=0.0).clamp(min=0)\n",
    "\n",
    "    plots_v2.plot_eval(batch, un_preds, Path(\".\"), n_species_to_plot=1, save=False)\n",
    "    print(\"Preds shape\", unnormalized_preds.shape)\n",
    "    # ---- metrics ------------------------------------------------------ #\n",
    "    un_preds = un_preds.squeeze(0) # Remove the batch dim\n",
    "    target_yr2 = batch[\"species_distribution\"][:, 1]  # second year\n",
    "    crps_sum += UM.crps(un_preds, target_yr2).item()\n",
    "    dev = UM.poisson_deviance(un_preds, target_yr2)\n",
    "    d2_sum += UM.explained_deviance(un_preds, target_yr2).item()\n",
    "    dev_sum += dev.item()\n",
    "    tss_sum += UM.tss(un_preds, target_yr2).item()\n",
    "    n += 1\n",
    "metrics = {\n",
    "    \"CRPS\": crps_sum / n,\n",
    "    \"PoissonDev\": dev_sum / n,\n",
    "    \"D2\": d2_sum / n,\n",
    "    \"TSS\": tss_sum / n,\n",
    "}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bfm_finetune.vis_tools import plot_change_map, plot_confusion_map, plot_taylor_single, plot_hexbin, plot_error_violin\n",
    "lon = batch[\"metadata\"][\"lon\"].cpu().numpy()\n",
    "lat = batch[\"metadata\"][\"lat\"].cpu().numpy()\n",
    "species_i = 42\n",
    "\n",
    "species_subset = [0, 1, 2] # select species\n",
    "for s in species_subset:\n",
    "    y0       = batch[\"species_distribution\"][0, 0, s].cpu()\n",
    "    y1_true  = batch[\"species_distribution\"][0, 1, s].cpu()\n",
    "    y1_pred  = un_preds[0, s].cpu()\n",
    "    plot_change_map(lat, lon, y0, y1_true, y1_pred, s)\n",
    "    # plot_taylor(lat, lon, y1_true.numpy(), y1_pred.numpy())\n",
    "    # plot_taylor_single(y0.numpy().ravel(), y1_pred.numpy().ravel(), title=\"Yearâ€‘1 spatial skill\")\n",
    "    plot_confusion_map(lat, lon, y1_true.numpy(), y1_pred.numpy())\n",
    "\n",
    "# global calibration\n",
    "obs_all  = batch[\"species_distribution\"][:, 1].reshape(-1).cpu()\n",
    "pred_all = un_preds.reshape(-1).cpu()\n",
    "plot_hexbin(pred_all, obs_all)\n",
    "\n",
    "# violin of absolute errors  [species, cells]\n",
    "abs_err = torch.abs(un_preds - batch[\"species_distribution\"][:, 1]).cpu()\n",
    "plot_error_violin(abs_err.reshape(500, -1).numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
