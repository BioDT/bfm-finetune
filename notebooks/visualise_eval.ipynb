{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkhan/bfm-finetune/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "STORAGE_DIR: /projects/prjs1134/data/projects/biodt/storage\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from aurora import Aurora\n",
    "\n",
    "from bfm_finetune.aurora_mod import AuroraFlex\n",
    "from bfm_finetune.plots import plot_eval\n",
    "from bfm_finetune.dataloaders.geolifeclef_species.dataloader import GeoLifeCLEFSpeciesDataset\n",
    "from bfm_finetune.dataloaders.dataloader_utils import custom_collate_fn\n",
    "from bfm_finetune.utils import load_checkpoint, seed_everything\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized AuroraFlex Mod\n",
      "files 1\n"
     ]
    }
   ],
   "source": [
    "base_model = Aurora(use_lora=False) # stabilise_level_agg=True\n",
    "base_model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-pretrained.ckpt\", strict=False) # strict=False\n",
    "atmos_levels = (50, 100, 150, 200, 250, 300, 400, 500, 600, 700, 850, 925, 1000)\n",
    "base_model.to(device)\n",
    "\n",
    "num_species = 500\n",
    "\n",
    "model = AuroraFlex(base_model=base_model, in_channels=num_species, hidden_channels=160,\n",
    "                    out_channels=num_species, atmos_levels=atmos_levels)\n",
    "model.to(device)\n",
    "\n",
    "val_dataset = GeoLifeCLEFSpeciesDataset(num_species=num_species, mode=\"val\")\n",
    "val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        collate_fn=custom_collate_fn,\n",
    "        num_workers=1,\n",
    "    )\n",
    "\n",
    "params_to_optimize = model.parameters()\n",
    "optimizer = torch.optim.AdamW(params_to_optimize, lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid checkpoint loaded: Error(s) in loading state_dict for AuroraFlex:\n",
      "\tsize mismatch for base_model.encoder.atmos_latents: copying a param with shape torch.Size([3, 256]) from checkpoint, the shape in current model is torch.Size([3, 512]).\n",
      "\tsize mismatch for base_model.encoder.surf_level_encoding: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.encoder.surf_mlp.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.encoder.surf_mlp.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.encoder.surf_mlp.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
      "\tsize mismatch for base_model.encoder.surf_mlp.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.encoder.surf_norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.encoder.surf_norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.encoder.pos_embed.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
      "\tsize mismatch for base_model.encoder.pos_embed.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.encoder.scale_embed.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
      "\tsize mismatch for base_model.encoder.scale_embed.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.encoder.lead_time_embed.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
      "\tsize mismatch for base_model.encoder.lead_time_embed.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.encoder.absolute_time_embed.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
      "\tsize mismatch for base_model.encoder.absolute_time_embed.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.encoder.atmos_levels_embed.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
      "\tsize mismatch for base_model.encoder.atmos_levels_embed.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.encoder.surf_token_embeds.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.encoder.surf_token_embeds.weights.10u: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n",
      "\tsize mismatch for base_model.encoder.surf_token_embeds.weights.10v: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n",
      "\tsize mismatch for base_model.encoder.surf_token_embeds.weights.2t: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n",
      "\tsize mismatch for base_model.encoder.surf_token_embeds.weights.lsm: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n",
      "\tsize mismatch for base_model.encoder.surf_token_embeds.weights.msl: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n",
      "\tsize mismatch for base_model.encoder.surf_token_embeds.weights.slt: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n",
      "\tsize mismatch for base_model.encoder.surf_token_embeds.weights.z: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n",
      "\tsize mismatch for base_model.encoder.atmos_token_embeds.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.encoder.atmos_token_embeds.weights.q: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n",
      "\tsize mismatch for base_model.encoder.atmos_token_embeds.weights.t: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n",
      "\tsize mismatch for base_model.encoder.atmos_token_embeds.weights.u: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n",
      "\tsize mismatch for base_model.encoder.atmos_token_embeds.weights.v: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n",
      "\tsize mismatch for base_model.encoder.atmos_token_embeds.weights.z: copying a param with shape torch.Size([256, 1, 2, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 1, 2, 4, 4]).\n",
      "\tsize mismatch for base_model.encoder.level_agg.layers.0.0.to_q.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
      "\tsize mismatch for base_model.encoder.level_agg.layers.0.0.to_kv.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n",
      "\tsize mismatch for base_model.encoder.level_agg.layers.0.0.to_out.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
      "\tsize mismatch for base_model.encoder.level_agg.layers.0.1.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.encoder.level_agg.layers.0.1.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.encoder.level_agg.layers.0.1.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
      "\tsize mismatch for base_model.encoder.level_agg.layers.0.1.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.encoder.level_agg.layers.0.2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.encoder.level_agg.layers.0.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.encoder.level_agg.layers.0.3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.encoder.level_agg.layers.0.3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.backbone.time_mlp.0.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
      "\tsize mismatch for base_model.backbone.time_mlp.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.backbone.time_mlp.2.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
      "\tsize mismatch for base_model.backbone.time_mlp.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.0.attn.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.0.attn.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.1.attn.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.1.attn.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.downsample.reduction.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.downsample.norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.0.downsample.norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.0.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.0.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.1.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.1.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.2.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.2.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.2.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.2.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.2.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.2.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.2.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.2.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.2.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.2.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.2.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.2.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.3.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.3.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.3.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.3.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.3.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.3.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.3.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.3.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.3.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.3.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.3.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.3.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.4.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.4.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.4.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.4.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.4.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.4.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.4.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.4.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.4.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.4.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.4.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.4.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.5.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.5.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.5.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.5.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.5.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.5.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.5.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.5.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.5.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.5.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.5.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.blocks.5.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.downsample.reduction.weight: copying a param with shape torch.Size([1024, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.downsample.norm.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.1.downsample.norm.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([6144, 2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.0.attn.proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.0.attn.proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([8192]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([1024, 4096]) from checkpoint, the shape in current model is torch.Size([2048, 8192]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([6144, 2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.1.attn.proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.1.attn.proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([8192]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([1024, 4096]) from checkpoint, the shape in current model is torch.Size([2048, 8192]).\n",
      "\tsize mismatch for base_model.backbone.encoder_layers.2.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([6144, 2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.0.attn.proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.0.attn.proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([8192]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([1024, 4096]) from checkpoint, the shape in current model is torch.Size([2048, 8192]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([6144, 2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.1.attn.proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.1.attn.proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([2048, 256]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([8192]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([1024, 4096]) from checkpoint, the shape in current model is torch.Size([2048, 8192]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.upsample.lin1.weight: copying a param with shape torch.Size([2048, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.upsample.lin2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.upsample.norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.0.upsample.norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.0.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.0.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.1.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.1.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.2.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.2.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.2.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.2.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.2.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.2.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.2.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.2.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.2.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.2.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.2.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.2.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.3.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.3.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.3.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.3.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.3.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.3.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.3.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.3.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.3.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.3.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.3.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.3.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.4.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.4.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.4.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.4.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.4.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.4.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.4.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.4.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.4.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.4.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.4.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.4.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.5.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.5.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.5.attn.qkv.weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.5.attn.qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.5.attn.proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.5.attn.proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.5.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.5.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.5.mlp.fc1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.5.mlp.fc1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.5.mlp.fc2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.blocks.5.mlp.fc2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.upsample.lin1.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.upsample.lin2.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.upsample.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.1.upsample.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.0.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.0.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.0.attn.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.0.attn.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.0.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.0.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.1.norm1.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.1.norm1.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([1536, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.1.attn.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.1.attn.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.1.norm2.ln_modulation.1.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.1.norm2.ln_modulation.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).\n",
      "\tsize mismatch for base_model.backbone.decoder_layers.2.blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for base_model.decoder.level_decoder.layers.0.0.to_q.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.decoder.level_decoder.layers.0.0.to_kv.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n",
      "\tsize mismatch for base_model.decoder.level_decoder.layers.0.0.to_out.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.decoder.level_decoder.layers.0.1.net.0.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n",
      "\tsize mismatch for base_model.decoder.level_decoder.layers.0.1.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for base_model.decoder.level_decoder.layers.0.1.net.2.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 2048]).\n",
      "\tsize mismatch for base_model.decoder.level_decoder.layers.0.1.net.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.decoder.level_decoder.layers.0.2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.decoder.level_decoder.layers.0.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.decoder.level_decoder.layers.0.3.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.decoder.level_decoder.layers.0.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for base_model.decoder.surf_heads.10u.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n",
      "\tsize mismatch for base_model.decoder.surf_heads.10v.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n",
      "\tsize mismatch for base_model.decoder.surf_heads.2t.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n",
      "\tsize mismatch for base_model.decoder.surf_heads.msl.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n",
      "\tsize mismatch for base_model.decoder.atmos_heads.q.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n",
      "\tsize mismatch for base_model.decoder.atmos_heads.t.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n",
      "\tsize mismatch for base_model.decoder.atmos_heads.u.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n",
      "\tsize mismatch for base_model.decoder.atmos_heads.v.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n",
      "\tsize mismatch for base_model.decoder.atmos_heads.z.weight: copying a param with shape torch.Size([16, 512]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n",
      "\tsize mismatch for base_model.decoder.atmos_levels_embed.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n",
      "\tsize mismatch for base_model.decoder.atmos_levels_embed.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for encoder.final_conv.weight: copying a param with shape torch.Size([27, 64, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([72, 64, 1, 3, 3]).\n",
      "\tsize mismatch for encoder.final_conv.bias: copying a param with shape torch.Size([27]) from checkpoint, the shape in current model is torch.Size([72]).\n",
      "\tsize mismatch for encoder.upsample_net.up1.weight: copying a param with shape torch.Size([27, 27, 1, 2, 2]) from checkpoint, the shape in current model is torch.Size([72, 72, 1, 2, 2]).\n",
      "\tsize mismatch for encoder.upsample_net.up1.bias: copying a param with shape torch.Size([27]) from checkpoint, the shape in current model is torch.Size([72]).\n",
      "\tsize mismatch for encoder.upsample_net.up2.weight: copying a param with shape torch.Size([27, 27, 1, 2, 2]) from checkpoint, the shape in current model is torch.Size([72, 72, 1, 2, 2]).\n",
      "\tsize mismatch for encoder.upsample_net.up2.bias: copying a param with shape torch.Size([27]) from checkpoint, the shape in current model is torch.Size([72]).\n",
      "\tsize mismatch for encoder.upsample_net.conv_adjust.weight: copying a param with shape torch.Size([27, 27, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([72, 72, 1, 3, 3]).\n",
      "\tsize mismatch for encoder.upsample_net.conv_adjust.bias: copying a param with shape torch.Size([27]) from checkpoint, the shape in current model is torch.Size([72]).\n",
      "\tsize mismatch for decoder.conv1.weight: copying a param with shape torch.Size([64, 27, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 72, 1, 3, 3]).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 5, 13, 2, 721, 1440]' is invalid for input of size 6323200",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m target = sample[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     prediction = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m plot_eval(\n\u001b[32m     17\u001b[39m     batch=batch,\n\u001b[32m     18\u001b[39m     prediction_species=prediction,\n\u001b[32m     19\u001b[39m     out_dir=\u001b[33m\"\u001b[39m\u001b[33mplots_dir\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m     save=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     21\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/home1/tkhan/bfm-finetune/bfm_finetune/aurora_mod.py:273\u001b[39m, in \u001b[36mAuroraFlex.forward\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    271\u001b[39m x = batch\n\u001b[32m    272\u001b[39m \u001b[38;5;66;03m# Encode input\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m encoded_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[38;5;66;03m# Pass through the Aurora model\u001b[39;00m\n\u001b[32m    275\u001b[39m aurora_output = \u001b[38;5;28mself\u001b[39m.base_model(encoded_input)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bfm-finetune/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bfm-finetune/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/home1/tkhan/bfm-finetune/bfm_finetune/new_variable_decoder.py:564\u001b[39m, in \u001b[36mInputMapper.forward\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    562\u001b[39m atmos = x_out[:, \u001b[32m7\u001b[39m:, :, :, :]\n\u001b[32m    563\u001b[39m \u001b[38;5;66;03m# Reshape to [B, 5, num_atmos_levels, T, H, W] then permute to [B, T, 5, num_atmos_levels, H, W]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m atmos = \u001b[43matmos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_atmos_levels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgeo_size\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgeo_size\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.permute(\u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m)\n\u001b[32m    565\u001b[39m keys_atmos = (\u001b[33m\"\u001b[39m\u001b[33mt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mu\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mq\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mz\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    566\u001b[39m atmos_vars = {k: atmos[:, :, i, :, :, :] \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(keys_atmos)}\n",
      "\u001b[31mRuntimeError\u001b[39m: shape '[1, 5, 13, 2, 721, 1440]' is invalid for input of size 6323200"
     ]
    }
   ],
   "source": [
    "PATH = \"/home/tkhan/bfm-finetune/outputs/2025-04-08/11-12-37/checkpoints/best_checkpoint.pth\"\n",
    "#_, _ = load_checkpoint(model, optimizer, PATH)\n",
    "try:\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "except Exception as e:\n",
    "    print(\"No valid checkpoint loaded:\", e)\n",
    "\n",
    "\n",
    "for sample in val_dataloader:\n",
    "    batch = sample[\"batch\"].to(device)\n",
    "    target = sample[\"target\"]\n",
    "    with torch.inference_mode():\n",
    "        prediction = model.forward(batch)\n",
    "    plot_eval(\n",
    "        batch=batch,\n",
    "        prediction_species=prediction,\n",
    "        out_dir=\"plots_dir\",\n",
    "        save=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
